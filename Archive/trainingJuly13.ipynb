{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, utils\n",
    "\n",
    "from getdist import plots, MCSamples\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Network import Generator, Discriminator\n",
    "from Signal_Generator import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for i in range(16000):\n",
    "    SG = Signal_Generator(num_sources=1, noise_amplitude=0)\n",
    "    signals = SG.generating_signal()\n",
    "    params = SG.printing_parameters()\n",
    "    signal = signals['Signal'].values\n",
    "\n",
    "    signal_tensor = torch.tensor(signal, dtype=torch.float).unsqueeze(0).to(device)\n",
    "    params_tensor = torch.tensor(params, dtype=torch.float).to(device)\n",
    "\n",
    "    dataset.append((signal_tensor, params_tensor))\n",
    "\n",
    "train_loader = utils.data.DataLoader(dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "num_latent_variables = 20\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, dataset, num_latent_variables, lr):\n",
    "        self.dataset = dataset\n",
    "        self.num_latent_variables = num_latent_variables\n",
    "        self.lr = lr\n",
    "\n",
    "        # Networks\n",
    "        self.generator = Generator(in_channels=1, num_latent_variables=num_latent_variables, length=len(signal), num_parameters=len(params)).to(device)\n",
    "        self.discriminator = Discriminator(input_channels=1, length=len(signal), num_parameters=len(params)).to(device)\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer_g = optim.Adam(self.generator.parameters(), lr=self.lr)\n",
    "        self.optimizer_d = optim.Adam(self.discriminator.parameters(), lr=self.lr)\n",
    "\n",
    "    def adversarial_loss(self, output_d, y):\n",
    "        return self.criterion(output_d, y)\n",
    "    \n",
    "    def train_generator(self, signal_tensor, z):\n",
    "        generated_params = self.generator(signal_tensor, z)\n",
    "        fake_output = self.discriminator(signal_tensor, generated_params)\n",
    "        g_loss = self.adversarial_loss(fake_output, torch.ones_like(fake_output))\n",
    "\n",
    "        self.optimizer_g.zero_grad()\n",
    "        g_loss.backward()\n",
    "        self.optimizer_g.step()\n",
    "\n",
    "        return g_loss.item()\n",
    "    \n",
    "    def train_discriminator(self, signal_tensor, params_tensor, z):\n",
    "        fake_params = self.generator(signal_tensor, z).detach()\n",
    "        real_output = self.discriminator(signal_tensor, params_tensor)\n",
    "        fake_output = self.discriminator(signal_tensor, fake_params)\n",
    "\n",
    "        real_loss = self.adversarial_loss(real_output, torch.ones_like(real_output))\n",
    "        fake_loss = self.adversarial_loss(fake_output, torch.zeros_like(fake_output))\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "        self.optimizer_d.zero_grad()\n",
    "        d_loss.backward()\n",
    "        self.optimizer_d.step()\n",
    "\n",
    "        return d_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(dataset, num_latent_variables=num_latent_variables, lr=learning_rate)\n",
    "\n",
    "d_loss_list = []\n",
    "# Train the GAN\n",
    "for i in range(200):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        d_loss = gan.train_discriminator(signal_tensor, params_tensor, z)\n",
    "        d_loss_list.append(d_loss)\n",
    "    #print(f\"Epoch {i}, Discriminator loss: {d_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_loss_list)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(dataset, num_latent_variables=num_latent_variables, lr=learning_rate)\n",
    "\n",
    "g_loss_list = []\n",
    "# Train the GAN\n",
    "for i in range(10):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        g_loss = gan.train_generator(signal_tensor, z)\n",
    "        g_loss_list.append(g_loss)\n",
    "    #print(f\"Epoch {i}, Discriminator loss: {g_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(g_loss_list)\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN(dataset, num_latent_variables=num_latent_variables, lr=learning_rate)\n",
    "g_loss_list = []\n",
    "d_loss_list = []\n",
    "\n",
    "num_epochs = 50\n",
    "num_discriminator = 3\n",
    "num_generator = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "\n",
    "        for _ in range(num_discriminator):\n",
    "            g_loss = gan.train_generator(signal_tensor, z)\n",
    "            g_loss_list.append(g_loss)\n",
    "\n",
    "        for _ in range(num_generator):\n",
    "            d_loss = gan.train_discriminator(signal_tensor, params_tensor, z)\n",
    "            d_loss_list.append(d_loss)\n",
    "    print(f\"Epoch {epoch}, Generator loss: {g_loss}, Discriminator loss: {d_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = gan.generator\n",
    "generator.eval()\n",
    "\n",
    "for i in range(10):\n",
    "    TS = Signal_Generator(num_sources=1, noise_amplitude=1)\n",
    "    test_data = TS.generating_signal()\n",
    "    params = TS.printing_parameters()\n",
    "\n",
    "    input_signal = test_data['Signal'].values\n",
    "    input_signal_tensor = torch.tensor(input_signal, dtype=torch.float).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_params = generator(input_signal_tensor, z).squeeze().cpu().numpy()\n",
    "\n",
    "    print(params)\n",
    "    print(generated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN(torch.nn.Module):\n",
    "    def __init__(self, num_latent_variables, lr, weight_clip):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.num_latent_variables = num_latent_variables\n",
    "        self.lr = lr\n",
    "        self.weight_clip = weight_clip\n",
    "\n",
    "        # Networks\n",
    "        self.generator = Generator(in_channels=1, num_latent_variables=num_latent_variables, length=len(signal), num_parameters=len(params)).to(device)\n",
    "        self.discriminator = Discriminator(input_channels=1, length=len(signal), num_parameters=len(params)).to(device)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer_g = optim.Adam(self.generator.parameters(), lr=self.lr)\n",
    "        self.optimizer_d = optim.Adam(self.discriminator.parameters(), lr=self.lr)\n",
    "\n",
    "    def wasserstein_loss(self, output_d, y):\n",
    "        return torch.mean(output_d * y)\n",
    "    \n",
    "    def train_generator(self, signal_tensor, params_tensor, z):\n",
    "        fake_params = self.generator(signal_tensor, z)\n",
    "        fake_output = self.discriminator(signal_tensor, fake_params)\n",
    "        real_output = self.discriminator(signal_tensor, params_tensor)\n",
    "        g_loss = -torch.mean(fake_output)\n",
    "        d_loss = -(torch.mean(real_output) - torch.mean(fake_output))\n",
    "\n",
    "        self.optimizer_g.zero_grad()\n",
    "        g_loss.backward()\n",
    "        self.optimizer_g.step()\n",
    "\n",
    "        return g_loss.item(), d_loss.item()\n",
    "    \n",
    "    def train_discriminator(self, signal_tensor, params_tensor, z):\n",
    "        fake_params = self.generator(signal_tensor, z)\n",
    "        fake_output = self.discriminator(signal_tensor, fake_params)\n",
    "        real_output = self.discriminator(signal_tensor, params_tensor)\n",
    "        g_loss = -torch.mean(fake_output)\n",
    "        d_loss = -(torch.mean(real_output) - torch.mean(fake_output))\n",
    "\n",
    "        self.optimizer_d.zero_grad()\n",
    "        d_loss.backward()\n",
    "        self.optimizer_d.step()\n",
    "\n",
    "        # Weight clipping\n",
    "        for p in self.discriminator.parameters():\n",
    "            p.data.clamp_(-self.weight_clip, self.weight_clip)\n",
    "\n",
    "        return g_loss.item(), d_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = WGAN(dataset, num_latent_variables=num_latent_variables, lr=learning_rate, weight_clip=0.1).to(device)\n",
    "\n",
    "loss_list = []\n",
    "# Train the GAN\n",
    "for i in tqdm(range(100)):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        loss = wgan.train_discriminator(signal_tensor, params_tensor, z)\n",
    "        loss_list.append(loss)\n",
    "    #print(f\"Epoch {i}, Discriminator loss: {d_loss}\")\n",
    "\n",
    "plt.plot(loss_list, label=['Generator Loss', 'Discriminator Loss'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = WGAN(dataset, num_latent_variables=num_latent_variables, lr=learning_rate, weight_clip=0.1)\n",
    "\n",
    "loss_list = []\n",
    "for i in range(10):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        loss = wgan.train_discriminator(signal_tensor, params_tensor, z)\n",
    "        loss_list.append(loss)\n",
    "\n",
    "for i in range(3):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        loss = wgan.train_generator(signal_tensor, params_tensor, z)\n",
    "        loss_list.append(loss)\n",
    "    #print(f\"Epoch {i}, Discriminator loss: {g_loss}\")\n",
    "\n",
    "for i in range(10):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        loss = wgan.train_discriminator(signal_tensor, params_tensor, z)\n",
    "        loss_list.append(loss)\n",
    "\n",
    "plt.plot(loss_list, label=['Generator Loss', 'Discriminator Loss'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan = WGAN(num_latent_variables=num_latent_variables, lr=learning_rate, weight_clip=0.1).to(device)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "ncri_list = []\n",
    "ngen_list = []\n",
    "\n",
    "d_loss_threshold = -0.1\n",
    "g_loss_threshold = -0.3\n",
    "\n",
    "loss_adjustment = 0.025\n",
    "max_steps = 300\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "training_d = True\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    ncri = 0\n",
    "    ngen = 0\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        signal_tensor = signal_tensor.to(device)\n",
    "        params_tensor = params_tensor.to(device)\n",
    "\n",
    "        critic_steps = 0\n",
    "        generator_steps = 0\n",
    "        \n",
    "        while training_d and critic_steps < max_steps:\n",
    "            loss = wgan.train_discriminator(signal_tensor, params_tensor, z)\n",
    "            loss_list.append(loss)\n",
    "            ncri+=1\n",
    "            critic_steps+=1\n",
    "            if loss[0] > g_loss_threshold:\n",
    "                training_d = False\n",
    "                break\n",
    "\n",
    "        if critic_steps == max_steps:\n",
    "            g_loss_threshold -= loss_adjustment\n",
    "\n",
    "        while not training_d and generator_steps < max_steps:\n",
    "            loss = wgan.train_generator(signal_tensor, params_tensor, z)\n",
    "            loss_list.append(loss)\n",
    "            ngen+=1\n",
    "            generator_steps+=1\n",
    "            if loss[1] > d_loss_threshold:\n",
    "                training_d = True\n",
    "                break\n",
    "\n",
    "        if generator_steps == max_steps:\n",
    "            d_loss_threshold -= loss_adjustment\n",
    "\n",
    "    ncri_list.append(ncri)\n",
    "    ngen_list.append(ngen)\n",
    "\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs}, Generator loss: {loss[0]}, Discriminator loss: {loss[1]}\")\n",
    "\n",
    "plt.plot(loss_list, label=['Generator Loss', 'Discriminator Loss'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ncri_list, label='Number of critic steps')\n",
    "plt.title('Number of critic steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ngen_list, label='Number of generator steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "\n",
    "        loss = wgan.train_generator(signal_tensor, params_tensor, z)\n",
    "        loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = wgan.generator\n",
    "generator.eval()\n",
    "\n",
    "generated_params_list = []\n",
    "\n",
    "TS = Signal_Generator(num_sources=1, noise_amplitude=1)\n",
    "test_data = TS.generating_signal()\n",
    "params = TS.printing_parameters()\n",
    "\n",
    "input_signal = test_data['Signal'].values\n",
    "input_signal_tensor = torch.tensor(input_signal, dtype=torch.float).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "for i in range(10000):\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        generated_params = generator(input_signal_tensor, z).squeeze().cpu().numpy()\n",
    "\n",
    "    generated_params_list.append(generated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_params_df = pd.DataFrame(generated_params_list, columns=['Amplitude', 'Frequency', 'Phase'])\n",
    "\n",
    "names = [\"A\",\"omega\",\"theta\"]\n",
    "labels =  [\"Amplitude\",\"frequency\",\"phase\"]\n",
    "\n",
    "generated_params_samples = MCSamples(samples=generated_params_df.values, names=names, labels=labels, settings={'ignore_rows': 1000})\n",
    "#samples.setRanges([[-3,3],[-3,3]])\n",
    "generated_params_samples.updateSettings({'fine_bins_2D': 1048})\n",
    "\n",
    "g = plots.get_subplot_plotter()\n",
    "\n",
    "g.triangle_plot([generated_params_samples], filled=True)\n",
    "\n",
    "axes = g.subplots\n",
    "\n",
    "for i in range(len(names)):\n",
    "    for j in range(i+1, len(names)):\n",
    "        ax = axes[j, i]\n",
    "        if ax is not None:\n",
    "            ax.scatter(params[i], params[j], color='red', marker='o', s=50)\n",
    "\n",
    "for i in range(len(names)):\n",
    "    ax = axes[i, i]\n",
    "    if ax is not None:\n",
    "        ax.axvline(params[i], linestyle='--', color='red', lw=1)\n",
    "\n",
    "handles = [plt.Line2D([0], [0], color='red', lw=2, linestyle='--', marker='o')]\n",
    "labels = ['Original Parameters']\n",
    "g.fig.legend(handles, labels, loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "#g.export('weight_clip_0.1for300epochs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = wgan.generator\n",
    "generator.eval()\n",
    "\n",
    "params_list = []\n",
    "generated_params_list = []\n",
    "\n",
    "test_times = 30\n",
    "for i in range(test_times):\n",
    "    TS = Signal_Generator(num_sources=1, noise_amplitude=1)\n",
    "    test_data = TS.generating_signal()\n",
    "    params = TS.printing_parameters()\n",
    "\n",
    "    input_signal = test_data['Signal'].values\n",
    "    input_signal_tensor = torch.tensor(input_signal, dtype=torch.float).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        generated_params = generator(input_signal_tensor, z).squeeze().cpu().numpy()\n",
    "\n",
    "    params_list.append(params)\n",
    "    generated_params_list.append(generated_params)\n",
    "\n",
    "    print(params)\n",
    "    print(generated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_amplitudes = [params[0] for params in params_list]\n",
    "actual_frequencies = [params[1] for params in params_list]\n",
    "actual_phases = [params[2] for params in params_list]\n",
    "\n",
    "generated_amplitudes = [gen_params[0] for gen_params in generated_params_list]\n",
    "generated_frequencies = [gen_params[1] for gen_params in generated_params_list]\n",
    "generated_phases = [gen_params[2] for gen_params in generated_params_list]\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(test_times), actual_amplitudes, 'o-', label='Actual Amplitudes')\n",
    "plt.plot(range(test_times), generated_amplitudes, 'x-', label='Generated Amplitudes')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Amplitude Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(test_times), actual_frequencies, 'o-', label='Actual Frequencies')\n",
    "plt.plot(range(test_times), generated_frequencies, 'x-', label='Generated Frequencies')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(test_times), actual_phases, 'o-', label='Actual Phases')\n",
    "plt.plot(range(test_times), generated_phases, 'x-', label='Generated Phases')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Phase')\n",
    "plt.title('Phase Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasLISA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
