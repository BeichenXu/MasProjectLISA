{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import torch\n",
    "from torch import optim, utils, tensor, nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from getdist import plots, MCSamples\n",
    "\n",
    "from Network import Generator, Discriminator\n",
    "from Signal_Generator import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setting the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters\n",
    "datasize = 16000\n",
    "num_sources = 1\n",
    "noise_amplitude = 0\n",
    "\n",
    "num_latent_variables = 20\n",
    "learning_rate = 1e-5\n",
    "weight_clip = 0.1\n",
    "\n",
    "num_epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the distribution for amplitude and angular frequency\n",
    "def amp_distribution(size):\n",
    "    \"\"\"\n",
    "    Amplitude distribution using uniform distribution.\n",
    "    \"\"\"\n",
    "    return np.random.uniform(6, 14, size=size)\n",
    "\n",
    "def omega_distribution(size):\n",
    "    \"\"\"\n",
    "    Angular frequency distribution using uniform distribution.\n",
    "    \"\"\"\n",
    "    return np.random.uniform(0.33, 0.67, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset\n",
    "dataset = []\n",
    "\n",
    "for i in range(datasize):\n",
    "    SG = Signal_Generator(num_sources=1, noise_amplitude=0, amp_distribution_func=amp_distribution, omega_distribution_func=omega_distribution)\n",
    "    signals = SG.generating_signal()\n",
    "    params = SG.printing_parameters()\n",
    "    signal = signals['Signal'].values\n",
    "\n",
    "    signal_tensor = tensor(signal, dtype=torch.float).unsqueeze(0).to(device)\n",
    "    params_tensor = tensor(params, dtype=torch.float).to(device)\n",
    "\n",
    "    dataset.append((signal_tensor, params_tensor))\n",
    "\n",
    "train_loader = utils.data.DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the WGAN traning class\n",
    "class WGAN(nn.Module):\n",
    "    def __init__(self, num_latent_variables, lr, weight_clip):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.num_latent_variables = num_latent_variables\n",
    "        self.lr = lr\n",
    "        self.weight_clip = weight_clip\n",
    "\n",
    "        # Networks\n",
    "        self.generator = Generator(in_channels=1, num_latent_variables=num_latent_variables, length=len(signal), num_parameters=len(params)).to(device)\n",
    "        self.discriminator = Discriminator(input_channels=1, length=len(signal), num_parameters=len(params)).to(device)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer_g = optim.Adam(self.generator.parameters(), lr=self.lr)\n",
    "        self.optimizer_d = optim.Adam(self.discriminator.parameters(), lr=self.lr)\n",
    "\n",
    "    def wasserstein_loss(self, output_d, y):\n",
    "        return torch.mean(output_d * y)\n",
    "    \n",
    "    def train_generator(self, signal_tensor, params_tensor, z):\n",
    "        fake_params = self.generator(signal_tensor, z)\n",
    "        fake_output = self.discriminator(signal_tensor, fake_params)\n",
    "        real_output = self.discriminator(signal_tensor, params_tensor)\n",
    "        g_loss = -torch.mean(fake_output)\n",
    "        d_loss = -(torch.mean(real_output) - torch.mean(fake_output))\n",
    "\n",
    "        self.optimizer_g.zero_grad()\n",
    "        g_loss.backward()\n",
    "        self.optimizer_g.step()\n",
    "\n",
    "        return g_loss.item(), d_loss.item()\n",
    "    \n",
    "    def train_discriminator(self, signal_tensor, params_tensor, z):\n",
    "        fake_params = self.generator(signal_tensor, z)\n",
    "        fake_output = self.discriminator(signal_tensor, fake_params)\n",
    "        real_output = self.discriminator(signal_tensor, params_tensor)\n",
    "        g_loss = -torch.mean(fake_output)\n",
    "        d_loss = -(torch.mean(real_output) - torch.mean(fake_output))\n",
    "\n",
    "        self.optimizer_d.zero_grad()\n",
    "        d_loss.backward()\n",
    "        self.optimizer_d.step()\n",
    "\n",
    "        # Weight clipping\n",
    "        for p in self.discriminator.parameters():\n",
    "            p.data.clamp_(-self.weight_clip, self.weight_clip)\n",
    "\n",
    "        return g_loss.item(), d_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Test training\\nwgan = WGAN(num_latent_variables=num_latent_variables, lr=learning_rate, weight_clip=0.1).to(device)\\n\\nloss_list = []\\n\\nfor i in tqdm(range(100)):\\n    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\\n        z = torch.randn(1, num_latent_variables, 1).to(device)\\n        loss = wgan.train_discriminator(signal_tensor, params_tensor, z)\\n        loss_list.append(loss)\\n    #print(f\"Epoch {i}, Discriminator loss: {d_loss}\")\\n\\nplt.plot(loss_list, label=[\\'Generator Loss\\', \\'Discriminator Loss\\'])\\nplt.legend() '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Test training\n",
    "wgan = WGAN(num_latent_variables=num_latent_variables, lr=learning_rate, weight_clip=0.1).to(device)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        loss = wgan.train_discriminator(signal_tensor, params_tensor, z)\n",
    "        loss_list.append(loss)\n",
    "    #print(f\"Epoch {i}, Discriminator loss: {d_loss}\")\n",
    "\n",
    "plt.plot(loss_list, label=['Generator Loss', 'Discriminator Loss'])\n",
    "plt.legend() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' wgan = WGAN(num_latent_variables=num_latent_variables, lr=learning_rate, weight_clip=0.1).to(device)\\n\\nloss_list = []\\n\\nfor i in tqdm(range(50)):\\n    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\\n        z = torch.randn(1, num_latent_variables, 1).to(device)\\n        loss = wgan.train_discriminator(signal_tensor, params_tensor, z)\\n        loss_list.append(loss)\\n    #print(f\"Epoch {i}, Discriminator loss: {d_loss}\")\\n\\nfor i in tqdm(range(50)):\\n    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\\n        z = torch.randn(1, num_latent_variables, 1).to(device)\\n        loss = wgan.train_generator(signal_tensor, params_tensor, z)\\n        loss_list.append(loss)\\n    #print(f\"Epoch {i}, Discriminator loss: {d_loss}\")\\n\\nplt.plot(loss_list, label=[\\'Generator Loss\\', \\'Discriminator Loss\\'])\\nplt.legend() '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" wgan = WGAN(num_latent_variables=num_latent_variables, lr=learning_rate, weight_clip=0.1).to(device)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for i in tqdm(range(50)):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        loss = wgan.train_discriminator(signal_tensor, params_tensor, z)\n",
    "        loss_list.append(loss)\n",
    "    #print(f\"Epoch {i}, Discriminator loss: {d_loss}\")\n",
    "\n",
    "for i in tqdm(range(50)):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        loss = wgan.train_generator(signal_tensor, params_tensor, z)\n",
    "        loss_list.append(loss)\n",
    "    #print(f\"Epoch {i}, Discriminator loss: {d_loss}\")\n",
    "\n",
    "plt.plot(loss_list, label=['Generator Loss', 'Discriminator Loss'])\n",
    "plt.legend() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1487/2000 [6:06:11<2:06:20, 14.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m     10\u001b[0m     z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, num_latent_variables, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 11\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mwgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_discriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     loss_list\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n",
      "Cell \u001b[1;32mIn[5], line 48\u001b[0m, in \u001b[0;36mWGAN.train_discriminator\u001b[1;34m(self, signal_tensor, params_tensor, z)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m     46\u001b[0m     p\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mclamp_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_clip, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_clip)\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mg_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, d_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Adaptive training\n",
    "wgan = WGAN(num_latent_variables=num_latent_variables, lr=learning_rate, weight_clip=0.1).to(device)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "       \n",
    "        for i in range(5):\n",
    "            z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "            loss = wgan.train_discriminator(signal_tensor, params_tensor, z)\n",
    "            loss_list.append(loss)\n",
    "\n",
    "        for i in range(1):\n",
    "            z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "            loss = wgan.train_generator(signal_tensor, params_tensor, z)\n",
    "            loss_list.append(loss)\n",
    "\n",
    "plt.plot(loss_list, label=['Generator Loss', 'Discriminator Loss'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = wgan.generator\n",
    "discriminator = wgan.discriminator\n",
    "\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_params_list = []\n",
    "\n",
    "TS = Signal_Generator(num_sources=1, noise_amplitude=0)\n",
    "test_data = TS.generating_signal()\n",
    "params = TS.printing_parameters()\n",
    "\n",
    "input_signal = test_data['Signal'].values\n",
    "input_signal_tensor = torch.tensor(input_signal, dtype=torch.float).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "for i in range(10000):\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        generated_params = generator(input_signal_tensor, z).squeeze().cpu().numpy()\n",
    "\n",
    "    generated_params_list.append(generated_params)\n",
    "\n",
    "print(params)\n",
    "print(generated_params_list)\n",
    "\n",
    "generated_params_df = pd.DataFrame(generated_params_list, columns=['Amplitude', 'Frequency', 'Phase'])\n",
    "\n",
    "names = [\"A\",\"omega\",\"theta\"]\n",
    "labels =  [\"Amplitude\",\"frequency\",\"phase\"]\n",
    "\n",
    "generated_params_samples = MCSamples(samples=generated_params_df.values, names=names, labels=labels, settings={'ignore_rows': 1000})\n",
    "generated_params_samples.updateSettings({'fine_bins_2D': 1048})\n",
    "\n",
    "g = plots.get_subplot_plotter()\n",
    "\n",
    "g.triangle_plot([generated_params_samples], filled=True)\n",
    "\n",
    "axes = g.subplots\n",
    "\n",
    "for i in range(len(names)):\n",
    "    for j in range(i+1, len(names)):\n",
    "        ax = axes[j, i]\n",
    "        if ax is not None:\n",
    "            ax.scatter(params[i], params[j], color='red', marker='o', s=50)\n",
    "\n",
    "for i in range(len(names)):\n",
    "    ax = axes[i, i]\n",
    "    if ax is not None:\n",
    "        ax.axvline(params[i], linestyle='--', color='red', lw=1)\n",
    "\n",
    "handles = [plt.Line2D([0], [0], color='red', lw=2, linestyle='--', marker='o')]\n",
    "labels = ['Original Parameters']\n",
    "g.fig.legend(handles, labels, loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = []\n",
    "generated_params_list = []\n",
    "\n",
    "test_times = 30\n",
    "for i in range(test_times):\n",
    "    TS = Signal_Generator(num_sources=1, noise_amplitude=0, amp_distribution_func=amp_distribution, omega_distribution_func=omega_distribution)\n",
    "    test_data = TS.generating_signal()\n",
    "    params = TS.printing_parameters()\n",
    "\n",
    "    input_signal = test_data['Signal'].values\n",
    "    input_signal_tensor = torch.tensor(input_signal, dtype=torch.float).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        generated_params = generator(input_signal_tensor, z).squeeze().cpu().numpy()\n",
    "\n",
    "    params_list.append(params)\n",
    "    generated_params_list.append(generated_params)\n",
    "\n",
    "    #print(params)\n",
    "    #print(generated_params)\n",
    "\n",
    "actual_amplitudes = [params[0] for params in params_list]\n",
    "actual_frequencies = [params[1] for params in params_list]\n",
    "actual_phases = [params[2] for params in params_list]\n",
    "\n",
    "generated_amplitudes = [gen_params[0] for gen_params in generated_params_list]\n",
    "generated_frequencies = [gen_params[1] for gen_params in generated_params_list]\n",
    "generated_phases = [gen_params[2] for gen_params in generated_params_list]\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(test_times), actual_amplitudes, 'o-', label='Actual Amplitudes')\n",
    "plt.plot(range(test_times), generated_amplitudes, 'x-', label='Generated Amplitudes')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Amplitude Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(test_times), actual_frequencies, 'o-', label='Actual Frequencies')\n",
    "plt.plot(range(test_times), generated_frequencies, 'x-', label='Generated Frequencies')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(test_times), actual_phases, 'o-', label='Actual Phases')\n",
    "plt.plot(range(test_times), generated_phases, 'x-', label='Generated Phases')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Phase')\n",
    "plt.title('Phase Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.suptitle(f'line chart with fixed z for {num_epochs} epochs and {len(loss_list)} steps', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(generator, 'generator_model.pt')\n",
    "#torch.save(discriminator, 'discriminator_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasLISA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
