{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import torch\n",
    "from torch import optim, utils, tensor, nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from getdist import plots, MCSamples\n",
    "\n",
    "from Network import Generator, Discriminator\n",
    "from Signal_Generator import *\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Setting the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hyperparameters\n",
    "datasize = 16000\n",
    "num_sources = 1\n",
    "noise_amplitude = 0\n",
    "\n",
    "num_latent_variables = 20\n",
    "learning_rate = 1e-5\n",
    "weight_clip = 0.1\n",
    "\n",
    "d_loss_threshold = -0.1\n",
    "g_loss_threshold = -0.3\n",
    "threshold_adjustment = 0.025\n",
    "max_steps = 300\n",
    "\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset\n",
    "dataset = []\n",
    "\n",
    "for i in range(datasize):\n",
    "    SG = Signal_Generator(num_sources=1, noise_amplitude=0)\n",
    "    signals = SG.generating_signal()\n",
    "    params = SG.printing_parameters()\n",
    "    signal = signals['Signal'].values\n",
    "\n",
    "    signal_tensor = tensor(signal, dtype=torch.float).unsqueeze(0).to(device)\n",
    "    params_tensor = tensor(params, dtype=torch.float).to(device)\n",
    "\n",
    "    dataset.append((signal_tensor, params_tensor))\n",
    "\n",
    "train_loader = utils.data.DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the WGAN traning class\n",
    "class WGAN(nn.Module):\n",
    "    def __init__(self, num_latent_variables, lr, weight_clip):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.num_latent_variables = num_latent_variables\n",
    "        self.lr = lr\n",
    "        self.weight_clip = weight_clip\n",
    "\n",
    "        # Networks\n",
    "        self.generator = Generator(in_channels=1, num_latent_variables=num_latent_variables, length=len(signal), num_parameters=len(params)).to(device)\n",
    "        self.discriminator = Discriminator(input_channels=1, length=len(signal), num_parameters=len(params)).to(device)\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer_g = optim.Adam(self.generator.parameters(), lr=self.lr)\n",
    "        self.optimizer_d = optim.Adam(self.discriminator.parameters(), lr=self.lr)\n",
    "\n",
    "    def wasserstein_loss(self, output_d, y):\n",
    "        return torch.mean(output_d * y)\n",
    "    \n",
    "    def train_generator(self, signal_tensor, params_tensor, z):\n",
    "        fake_params = self.generator(signal_tensor, z)\n",
    "        fake_output = self.discriminator(signal_tensor, fake_params)\n",
    "        real_output = self.discriminator(signal_tensor, params_tensor)\n",
    "        g_loss = -torch.mean(fake_output)\n",
    "        d_loss = -(torch.mean(real_output) - torch.mean(fake_output))\n",
    "\n",
    "        self.optimizer_g.zero_grad()\n",
    "        g_loss.backward()\n",
    "        self.optimizer_g.step()\n",
    "\n",
    "        return g_loss.item(), d_loss.item()\n",
    "    \n",
    "    def train_discriminator(self, signal_tensor, params_tensor, z):\n",
    "        fake_params = self.generator(signal_tensor, z)\n",
    "        fake_output = self.discriminator(signal_tensor, fake_params)\n",
    "        real_output = self.discriminator(signal_tensor, params_tensor)\n",
    "        g_loss = -torch.mean(fake_output)\n",
    "        d_loss = -(torch.mean(real_output) - torch.mean(fake_output))\n",
    "\n",
    "        self.optimizer_d.zero_grad()\n",
    "        d_loss.backward()\n",
    "        self.optimizer_d.step()\n",
    "\n",
    "        # Weight clipping\n",
    "        for p in self.discriminator.parameters():\n",
    "            p.data.clamp_(-self.weight_clip, self.weight_clip)\n",
    "\n",
    "        return g_loss.item(), d_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [01:10<02:28,  2.19s/it]"
     ]
    }
   ],
   "source": [
    "# Test training\n",
    "wgan = WGAN(num_latent_variables=num_latent_variables, lr=learning_rate, weight_clip=0.1).to(device)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        loss = wgan.train_discriminator(signal_tensor, params_tensor, z)\n",
    "        loss_list.append(loss)\n",
    "    #print(f\"Epoch {i}, Discriminator loss: {d_loss}\")\n",
    "\n",
    "plt.plot(loss_list, label=['Generator Loss', 'Discriminator Loss'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive training\n",
    "wgan = WGAN(num_latent_variables=num_latent_variables, lr=learning_rate, weight_clip=0.1).to(device)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "ncri_list = []\n",
    "ngen_list = []\n",
    "\n",
    "d_loss_threshold = -0.1\n",
    "g_loss_threshold = -0.3\n",
    "\n",
    "loss_adjustment = 0.025\n",
    "max_steps = 300\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "training_d = True\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    ncri = 0\n",
    "    ngen = 0\n",
    "    for _, (signal_tensor, params_tensor) in enumerate(train_loader):\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        signal_tensor = signal_tensor.to(device)\n",
    "        params_tensor = params_tensor.to(device)\n",
    "\n",
    "        critic_steps = 0\n",
    "        generator_steps = 0\n",
    "        \n",
    "        while training_d and critic_steps < max_steps:\n",
    "            loss = wgan.train_discriminator(signal_tensor, params_tensor, z)\n",
    "            loss_list.append(loss)\n",
    "            ncri+=1\n",
    "            critic_steps+=1\n",
    "            if loss[0] > g_loss_threshold:\n",
    "                training_d = False\n",
    "                break\n",
    "\n",
    "        if critic_steps == max_steps:\n",
    "            g_loss_threshold -= loss_adjustment\n",
    "\n",
    "        while not training_d and generator_steps < max_steps:\n",
    "            loss = wgan.train_generator(signal_tensor, params_tensor, z)\n",
    "            loss_list.append(loss)\n",
    "            ngen+=1\n",
    "            generator_steps+=1\n",
    "            if loss[1] > d_loss_threshold:\n",
    "                training_d = True\n",
    "                break\n",
    "\n",
    "        if generator_steps == max_steps:\n",
    "            d_loss_threshold -= loss_adjustment\n",
    "\n",
    "    ncri_list.append(ncri)\n",
    "    ngen_list.append(ngen)\n",
    "\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs}, Generator loss: {loss[0]}, Discriminator loss: {loss[1]}\")\n",
    "\n",
    "plt.plot(loss_list, label=['Generator Loss', 'Discriminator Loss'])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axs[0].plot(ncri_list, label='Number of critic steps', color='blue')\n",
    "axs[0].set_title('Number of critic steps')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Steps')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(ngen_list, label='Number of generator steps', color='red')\n",
    "axs[1].set_title('Number of generator steps')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Steps')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = wgan.generator\n",
    "generator.eval()\n",
    "\n",
    "generated_params_list = []\n",
    "\n",
    "TS = Signal_Generator(num_sources=1, noise_amplitude=1)\n",
    "test_data = TS.generating_signal()\n",
    "params = TS.printing_parameters()\n",
    "\n",
    "input_signal = test_data['Signal'].values\n",
    "input_signal_tensor = torch.tensor(input_signal, dtype=torch.float).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "for i in range(10000):\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        generated_params = generator(input_signal_tensor, z).squeeze().cpu().numpy()\n",
    "\n",
    "    generated_params_list.append(generated_params)\n",
    "\n",
    "print(params)\n",
    "print(generated_params_list)\n",
    "\n",
    "generated_params_df = pd.DataFrame(generated_params_list, columns=['Amplitude', 'Frequency', 'Phase'])\n",
    "\n",
    "names = [\"A\",\"omega\",\"theta\"]\n",
    "labels =  [\"Amplitude\",\"frequency\",\"phase\"]\n",
    "\n",
    "generated_params_samples = MCSamples(samples=generated_params_df.values, names=names, labels=labels, settings={'ignore_rows': 1000})\n",
    "#samples.setRanges([[-3,3],[-3,3]])\n",
    "generated_params_samples.updateSettings({'fine_bins_2D': 1048})\n",
    "\n",
    "g = plots.get_subplot_plotter()\n",
    "\n",
    "g.triangle_plot([generated_params_samples], filled=True)\n",
    "\n",
    "axes = g.subplots\n",
    "\n",
    "for i in range(len(names)):\n",
    "    for j in range(i+1, len(names)):\n",
    "        ax = axes[j, i]\n",
    "        if ax is not None:\n",
    "            ax.scatter(params[i], params[j], color='red', marker='o', s=50)\n",
    "\n",
    "for i in range(len(names)):\n",
    "    ax = axes[i, i]\n",
    "    if ax is not None:\n",
    "        ax.axvline(params[i], linestyle='--', color='red', lw=1)\n",
    "\n",
    "handles = [plt.Line2D([0], [0], color='red', lw=2, linestyle='--', marker='o')]\n",
    "labels = ['Original Parameters']\n",
    "g.fig.legend(handles, labels, loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = wgan.generator\n",
    "generator.eval()\n",
    "\n",
    "params_list = []\n",
    "generated_params_list = []\n",
    "\n",
    "test_times = 30\n",
    "for i in range(test_times):\n",
    "    TS = Signal_Generator(num_sources=1, noise_amplitude=1)\n",
    "    test_data = TS.generating_signal()\n",
    "    params = TS.printing_parameters()\n",
    "\n",
    "    input_signal = test_data['Signal'].values\n",
    "    input_signal_tensor = torch.tensor(input_signal, dtype=torch.float).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, num_latent_variables, 1).to(device)\n",
    "        generated_params = generator(input_signal_tensor, z).squeeze().cpu().numpy()\n",
    "\n",
    "    params_list.append(params)\n",
    "    generated_params_list.append(generated_params)\n",
    "\n",
    "    #print(params)\n",
    "    #print(generated_params)\n",
    "\n",
    "actual_amplitudes = [params[0] for params in params_list]\n",
    "actual_frequencies = [params[1] for params in params_list]\n",
    "actual_phases = [params[2] for params in params_list]\n",
    "\n",
    "generated_amplitudes = [gen_params[0] for gen_params in generated_params_list]\n",
    "generated_frequencies = [gen_params[1] for gen_params in generated_params_list]\n",
    "generated_phases = [gen_params[2] for gen_params in generated_params_list]\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(test_times), actual_amplitudes, 'o-', label='Actual Amplitudes')\n",
    "plt.plot(range(test_times), generated_amplitudes, 'x-', label='Generated Amplitudes')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Amplitude Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(test_times), actual_frequencies, 'o-', label='Actual Frequencies')\n",
    "plt.plot(range(test_times), generated_frequencies, 'x-', label='Generated Frequencies')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(test_times), actual_phases, 'o-', label='Actual Phases')\n",
    "plt.plot(range(test_times), generated_phases, 'x-', label='Generated Phases')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Phase')\n",
    "plt.title('Phase Comparison')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MasLISA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
